{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/end2end/lib/python3.12/site-packages/torch/_utils.py:842: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "/root/miniconda3/envs/end2end/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:366: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead\n",
      "  warnings.warn(\n",
      "/root/miniconda3/envs/end2end/lib/python3.12/inspect.py:586: UserWarning: The is_traceable field on torch.autograd.Function is deprecated and will be removed in PyTorch 2.4.\n",
      "  value = getter(object, key)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script src=\"https://spcl.github.io/dace-webclient/dist/sdfv.js\"></script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import statistics\n",
    "import subprocess\n",
    "import ctypes\n",
    "\n",
    "import sten\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import timeit\n",
    "import sys\n",
    "import time\n",
    "\n",
    "from grouped_nmv_tensor import SrNMTensor, nm_vector_mask_sparsify\n",
    "\n",
    "import spatha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = 64\n",
    "m = 16\n",
    "n = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7fcddd2f0890>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch. set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Dense computation implementation with torch.matmul()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Assuming the original matrix W has a shape of [2048 * 4096].\n",
    "\n",
    ">Assuming the original matrix X has a shape of [32768 * 2048].\n",
    "\n",
    ">Then, the shape of the matrix multiplication Y = XW is [32768 * 4096]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![pic1](For_the_example_notebook.png \"example\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After transposing the original matrix, a pruned_matrix is obtained by structured pruning according to the v:n:m scheme.\n",
    "\n",
    "The logic is as follows: Traverse each VxM block, first select 4 columns where non-zero elements can exist, and then randomly choose two columns from these four to fill in non-zero elements for each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vnm_random_pruning_torch(matrix, V, N, M):\n",
    "    \"\"\"\n",
    "    Perform v:n:m random structured pruning on a given matrix.\n",
    "\n",
    "    This function applies structured pruning to a matrix based on a specified VxM block configuration.\n",
    "    Within each block, 4 columns are randomly chosen as potential non-zero columns.\n",
    "    Then, for each row within the block, N out of these 4 columns are selected to retain non-zero elements from the original matrix.\n",
    "\n",
    "    Parameters:\n",
    "    - matrix (torch.Tensor): The original matrix to be pruned.\n",
    "    - V (int): Number of rows in each block.\n",
    "    - N (int): Number of columns to select for non-zero elements in each row.\n",
    "    - M (int): Total number of columns in each block.\n",
    "\n",
    "    Returns:\n",
    "    - torch.Tensor: A new matrix of the same shape as the input, with elements pruned according to the v:n:m scheme.\n",
    "    \"\"\"\n",
    "    rows, cols = matrix.shape\n",
    "    pruned_matrix = torch.zeros_like(matrix)\n",
    "\n",
    "    # Traverse each VxM block\n",
    "    for row_block in range(0, rows, V):\n",
    "        for col_block in range(0, cols, M):\n",
    "            # Randomly select 4 columns in each block as possible non-zero columns\n",
    "            possible_cols = torch.randperm(M)[:4] + col_block\n",
    "\n",
    "            # For each row, randomly select N columns from these 4 columns to fill in non-zero elements\n",
    "            for v_row in range(V):\n",
    "                selected_cols = possible_cols[torch.randperm(4)[:N]]\n",
    "                pruned_matrix[row_block + v_row, selected_cols] = matrix[row_block + v_row, selected_cols]\n",
    "\n",
    "    return pruned_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = torch.rand(4096, 2048, device=\"cuda:0\", dtype=torch.float16)\n",
    "\n",
    "torch.manual_seed(0)\n",
    "pruned_matrix = vnm_random_pruning_torch(matrix, v, n, m)\n",
    "pruned_matrix = pruned_matrix.to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the pruned matrix\n",
    "torch.save(pruned_matrix, \"pruned_matrix.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4096, 2048])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruned_matrix.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2048, 4096])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So the original matrix w is the transpose of pruned_matrix\n",
    "w = pruned_matrix.T\n",
    "w.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32768, 2048])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(size=(32768 ,2048), dtype=torch.float16, device='cuda:0')\n",
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32768, 4096])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.matmul(x, w)\n",
    "y.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.Perform sparse matrix computations using the spatha library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NMVectorSparsifier:\n",
    "    def __init__(self, n, m, tileM):\n",
    "        self.n = n\n",
    "        self.m = m\n",
    "        self.tileM = tileM\n",
    "\n",
    "    def __call__(self, tensor, grad_fmt=None):\n",
    "\n",
    "        mask, columns = nm_vector_mask_sparsify(tensor, self.n, self.m, self.tileM)\n",
    "        \n",
    "        sparse_mtx = sten.SparseTensorWrapper.wrapped_from_dense(\n",
    "            SrNMTensor(self.n, self.m, self.tileM, tensor, mask, columns, tensor.device),\n",
    "            tensor,\n",
    "            grad_fmt,\n",
    "        )\n",
    "\n",
    "        return sparse_mtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_dense_mul_dispatch(sparse_values, sparse_indices, sparse_metadata, dense, nrows_sp, ncols_sp, ncols_d, m, n, v, nnz):\n",
    "\n",
    "    dense_ = dense.contiguous()\n",
    "    #can not accept bias currently\n",
    "    bias = bias = torch.zeros(nrows_sp, dtype=torch.float16, device='cuda:0')\n",
    "    output = spatha.spmm(sparse_metadata,  # metadata\n",
    "                          sparse_indices,   # indices\n",
    "                          sparse_values,    # values\n",
    "                          dense_,           # rhs_matrix\n",
    "                          bias,\n",
    "                          nrows_sp,         # A_num_rows\n",
    "                          ncols_sp,         # A_num_cols\n",
    "                          ncols_d,          # B_num_cols\n",
    "                          v,                # vec_length\n",
    "                          n,                # n\n",
    "                          m,                # m\n",
    "                          nnz,              # nnz\n",
    "                          0,                # seed\n",
    "                          32,               # mbrow\n",
    "                          4                 # brow\n",
    "                          )\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_transpose = NMVectorSparsifier(n, m, v)(pruned_matrix).wrapped_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = torch.nn.Parameter(w_transpose.values)\n",
    "columns = w_transpose.columns\n",
    "metadata = w_transpose.metadata\n",
    "nrows_sp = w_transpose.nrows\n",
    "ncols_sp = w_transpose.ncols\n",
    "nnz      = w_transpose.nnz\n",
    "ncols_d = x.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = sparse_dense_mul_dispatch(values, columns, metadata, x.T, nrows_sp, ncols_sp,\n",
    "                                           ncols_d, m, n, v, nnz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32768, 4096])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Check if output and y are equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(output, y, atol=0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "end2end",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
